{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "sC1xRNljMjAQ"
      },
      "outputs": [],
      "source": [
        "from utils import *\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.set_device(0)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "-kUSy5zrMs7o"
      },
      "outputs": [],
      "source": [
        "def load_data(base_path=\"./data\"):\n",
        "    \"\"\" Load the data in PyTorch Tensor.\n",
        "\n",
        "    :return: (zero_train_matrix, train_data, valid_data, test_data)\n",
        "        WHERE:\n",
        "        zero_train_matrix: 2D sparse matrix where missing entries are\n",
        "        filled with 0.\n",
        "        train_data: 2D sparse matrix\n",
        "        valid_data: A dictionary {user_id: list,\n",
        "        user_id: list, is_correct: list}\n",
        "        test_data: A dictionary {user_id: list,\n",
        "        user_id: list, is_correct: list}\n",
        "    \"\"\"\n",
        "    train_matrix = load_train_sparse(base_path).toarray()\n",
        "    valid_data = load_valid_csv(base_path)\n",
        "    test_data = load_public_test_csv(base_path)\n",
        "\n",
        "    zero_train_matrix = train_matrix.copy()\n",
        "    # Fill in the missing entries to 0.\n",
        "    zero_train_matrix[np.isnan(train_matrix)] = 0\n",
        "    # Change to Float Tensor for PyTorch.\n",
        "    zero_train_matrix = torch.FloatTensor(zero_train_matrix)\n",
        "    train_matrix = torch.FloatTensor(train_matrix)\n",
        "\n",
        "    return zero_train_matrix, train_matrix, valid_data, test_data\n",
        "\n",
        "\n",
        "class AutoEncoder(nn.Module):\n",
        "    def __init__(self, num_question, k=100):\n",
        "        \"\"\" Initialize a class AutoEncoder.\n",
        "\n",
        "        :param num_question: int\n",
        "        :param k: int\n",
        "        \"\"\"\n",
        "        super(AutoEncoder, self).__init__()\n",
        "\n",
        "        # Define linear functions.\n",
        "        self.g = nn.Linear(num_question, k)\n",
        "        self.h = nn.Linear(k, num_question)\n",
        "\n",
        "    def get_weight_norm(self):\n",
        "        \"\"\" Return ||W^1||^2 + ||W^2||^2.\n",
        "\n",
        "        :return: float\n",
        "        \"\"\"\n",
        "        g_w_norm = torch.norm(self.g.weight, 2) ** 2\n",
        "        h_w_norm = torch.norm(self.h.weight, 2) ** 2\n",
        "        return g_w_norm + h_w_norm\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        \"\"\" Return a forward pass given inputs.\n",
        "\n",
        "        :param inputs: user vector.\n",
        "        :return: user vector.\n",
        "        \"\"\"\n",
        "        #####################################################################\n",
        "        # TODO:                                                             #\n",
        "        # Implement the function as described in the docstring.             #\n",
        "        # Use sigmoid activations for f and g.                              #\n",
        "        #####################################################################\n",
        "        out = torch.sigmoid(self.g(inputs))\n",
        "        out = torch.sigmoid(self.h(out))\n",
        "        #####################################################################\n",
        "        #                       END OF YOUR CODE                            #\n",
        "        #####################################################################\n",
        "        return out\n",
        "\n",
        "\n",
        "def train(model, lr, lamb, train_data, zero_train_data, valid_data, num_epoch):\n",
        "    \"\"\" Train the neural network, where the objective also includes\n",
        "    a regularizer.\n",
        "\n",
        "    :param model: Module\n",
        "    :param lr: float\n",
        "    :param lamb: float\n",
        "    :param train_data: 2D FloatTensor\n",
        "    :param zero_train_data: 2D FloatTensor\n",
        "    :param valid_data: Dict\n",
        "    :param num_epoch: int\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    # TODO: Add a regularizer to the cost function. \n",
        "    \n",
        "    # Tell PyTorch you are training the model.\n",
        "    model.train()\n",
        "\n",
        "    # Define optimizers and loss function.\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "    num_student = train_data.shape[0]\n",
        "\n",
        "    # For plotting\n",
        "    train_losses = []\n",
        "    valid_accuracies = []\n",
        "    epochs = []\n",
        "\n",
        "    for epoch in range(0, num_epoch):\n",
        "        train_loss = 0.\n",
        "\n",
        "        for user_id in range(num_student):\n",
        "            inputs = Variable(zero_train_data[user_id]).unsqueeze(0).to(device)\n",
        "            target = inputs.clone().to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(inputs)\n",
        "\n",
        "            # Mask the target to only compute the gradient of valid entries.\n",
        "            nan_mask = np.isnan(train_data[user_id].unsqueeze(0).numpy())\n",
        "            target[0][nan_mask] = output[0][nan_mask]\n",
        "\n",
        "            loss = torch.sum((output - target) ** 2.) + lamb/2*model.get_weight_norm()\n",
        "            loss.backward()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            optimizer.step()\n",
        "\n",
        "        valid_acc = evaluate(model, zero_train_data, valid_data)\n",
        "        print(\"Epoch: {} \\tTraining Cost: {:.6f} \\tValid Acc: {}\".format(epoch, train_loss, valid_acc))\n",
        "        \n",
        "        train_losses.append(train_loss)\n",
        "        valid_accuracies.append(valid_acc)\n",
        "        epochs.append(epoch)\n",
        "\n",
        "    # Plot training curve\n",
        "    fig, (ax1, ax2) = plt.subplots(2, sharex=True)\n",
        "\n",
        "    ax1.plot(epochs, train_losses)\n",
        "    ax1.set_title(\"Training Loss Curve\")\n",
        "    ax1.set(ylabel='Loss')\n",
        "\n",
        "    ax2.plot(epochs, valid_accuracies)\n",
        "    ax2.set_title(\"Validation Accuracy Curve\")\n",
        "    ax2.set(xlabel='Epochs', ylabel='Accuracy')\n",
        "\n",
        "    plt.subplots_adjust(hspace=0.5)\n",
        "    plt.show()\n",
        "\n",
        "    #####################################################################\n",
        "    #                       END OF YOUR CODE                            #\n",
        "    #####################################################################\n",
        "\n",
        "\n",
        "def evaluate(model, train_data, valid_data):\n",
        "    \"\"\" Evaluate the valid_data on the current model.\n",
        "\n",
        "    :param model: Module\n",
        "    :param train_data: 2D FloatTensor\n",
        "    :param valid_data: A dictionary {user_id: list,\n",
        "    question_id: list, is_correct: list}\n",
        "    :return: float\n",
        "    \"\"\"\n",
        "    # Tell PyTorch you are evaluating the model.\n",
        "    model.eval()\n",
        "\n",
        "    total = 0\n",
        "    correct = 0\n",
        "\n",
        "    for i, u in enumerate(valid_data[\"user_id\"]):\n",
        "        inputs = Variable(train_data[u]).unsqueeze(0).to(device)\n",
        "        output = model(inputs)\n",
        "\n",
        "        # Accuracy\n",
        "        guess = output[0][valid_data[\"question_id\"][i]].item() >= 0.5\n",
        "        if guess == valid_data[\"is_correct\"][i]:\n",
        "            correct += 1\n",
        "        total += 1\n",
        "\n",
        "    return correct / float(total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0 \tTraining Cost: 13804.152070 \tValid Acc: 0.6081004798193621\n",
            "Epoch: 1 \tTraining Cost: 12773.334682 \tValid Acc: 0.6234829240756421\n",
            "Epoch: 2 \tTraining Cost: 12419.077636 \tValid Acc: 0.6253175275190517\n",
            "Epoch: 3 \tTraining Cost: 12256.886973 \tValid Acc: 0.6271521309624611\n",
            "Epoch: 4 \tTraining Cost: 12121.042528 \tValid Acc: 0.6279988710132656\n",
            "Epoch: 5 \tTraining Cost: 11987.572649 \tValid Acc: 0.630962461191081\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-3-ab415405bae1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mlamb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlamb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzero_train_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;31m#####################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m#                       END OF YOUR CODE                            #\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-2-356a473d9e50>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, lr, lamb, train_data, zero_train_data, valid_data, num_epoch)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2.\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlamb\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_weight_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\Python39\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\Python39\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "zero_train_matrix, train_matrix, valid_data, test_data = load_data()\n",
        "\n",
        "#####################################################################\n",
        "# TODO:                                                             #\n",
        "# Try out 5 different k and select the best k using the             #\n",
        "# validation set.                                                   #\n",
        "#####################################################################\n",
        "\n",
        "\n",
        "# Set model hyperparameters.\n",
        "k = 50\n",
        "model = AutoEncoder(train_matrix.shape[1], k)\n",
        "model.to(device)\n",
        "\n",
        "# Set optimization hyperparameters.\n",
        "lr = 0.01\n",
        "num_epoch = 50\n",
        "lamb = 0\n",
        "\n",
        "train(model, lr, lamb, train_matrix, zero_train_matrix, valid_data, num_epoch)\n",
        "#####################################################################\n",
        "#                       END OF YOUR CODE                            #\n",
        "#####################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6917866215071973\n"
          ]
        }
      ],
      "source": [
        "test_acc = evaluate(model, zero_train_matrix, test_data)\n",
        "print(test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AutoEncoder(\n",
              "  (g): Linear(in_features=1774, out_features=50, bias=True)\n",
              "  (h): Linear(in_features=50, out_features=1774, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#torch.save(model.state_dict(), './model.pt')\n",
        "\n",
        "model = AutoEncoder(train_matrix.shape[1], k)\n",
        "model.load_state_dict(torch.load('./model.pt'))\n",
        "model.eval()\n",
        "model.to(device)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "neural_network.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
